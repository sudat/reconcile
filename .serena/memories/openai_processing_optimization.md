# OpenAI分類処理の最適化履歴

## 問題と解決策

### 元の問題（2025-01-11）
- **OpenAI APIリクエスト数**: 67回（部門×科目の組み合わせ）
- **並列処理**: 最大67プロセスが同時実行
- **コネクションプール問題**: 大量の同時接続でデータベース負荷

### 実装された解決策
**目標**: 67並列プロセス → 15部門単位並列プロセス（78%削減）

#### 1. 構造化出力スキーマの変更
**ファイル**: `app/actions/project-autogroup.ts`
- 従来: 取引先単位の結果
- 変更後: 科目別×取引先別の2次元構造
```typescript
// 新スキーマ: department_autogroup_result
{
  subjectResults: [{
    subjectCode: string,
    partnerResults: [{
      partnerCode: string,
      items: [{ memo: string, label: string }]
    }]
  }]
}
```

#### 2. データ取得の最適化
- **Entry取得**: 科目ループ削除、部門内全仕訳を一括取得
- **メモリ効率**: dataset単位（最大3000件程度）で軽微な負荷
- **データ整理**: 科目別×取引先別にメモリ内でグループ化

#### 3. OpenAI API呼び出しの統合
- **従来**: 科目ごとに1回のAPIリクエスト（67回）
- **変更後**: 部門ごとに1回のAPIリクエスト（15回）
- **ペイロード**: 約1万トークン（制限128Kの1/10程度）
- **入力データ**: 部門内全科目の取引先別摘要リスト

#### 4. 結果処理の改善
- AI結果を科目別に振り分け
- 科目ごとにProject・ProjectEntry作成
- 既存の2000件チャンク一括処理を維持

#### 5. エラーハンドリング強化
- 部門単位エラー時の科目別フォールバック
- APIキー未設定時の基本グループ化継続
- 詳細なワークフローログ

## 期待効果
- **OpenAI APIリクエスト**: 67回 → 15回（78%削減）
- **並列接続数**: 最大67 → 最大15
- **コネクションプール負荷**: 大幅軽減
- **処理時間**: 大幅短縮（API呼び出し回数減）

## 技術的なトレードオフ
- **メリット**: API効率化、データベース負荷軽減
- **リスク軽減**: dataset単位の処理でメモリ負荷軽微
- **可用性**: 複数レベルのフォールバック処理でサービス継続

## 実装原則
- **KISS**: シンプルな部門単位統合で最大効果
- **YAGNI**: 必要最小限の変更で目標達成
- **DRY**: 既存のDB一括処理ロジックを再利用